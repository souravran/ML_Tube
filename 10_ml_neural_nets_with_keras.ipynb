{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks with Keras\n",
    "\n",
    "\n",
    "Keras is a high-level Deep Learning API that allows you to easily build, train, evaluate, and execute all sorts of neural networks. To perform the heavy computations required by neural networks, it relies on a computation backend. At present, you can choose from three popular opensource Deep Learning libraries: TensorFlow, Microsoft Cognitive Toolkit\n",
    "(CNTK), and Theano.\n",
    "\n",
    "Moreover, TensorFlow itself now comes bundled with its own Keras implementation, tf.keras. It only supports TensorFlow as the backend, but it has the advantage of offering some very useful extra features, for example, it supports TensorFlow’s Data API, which makes it easy to load and preprocess data efficiently.\n",
    "\n",
    "\n",
    " - Building image classifier\n",
    " - Building regression MLP (_Multilayer Perceptron_)\n",
    " - Complex model with functional API\n",
    " - Subclassing API to build dynamic models\n",
    " - Saving and restoring model\n",
    " - Using callbacks in training\n",
    " - Tensorboard\n",
    " - __Hyperparameters tunig__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Setup\n",
    "\n",
    "Importing common modules. Using the Python3 as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "RESOURCE_DIR = os.path.join(PROJECT_ROOT_DIR, \"resource\")\n",
    "\n",
    "def save_fig(fig, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(RESOURCE_DIR, fig + \".\" + fig_extension)\n",
    "    print(\"Saving figure...\", fig)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Building an image classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's import TensorFlow and Keras.\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by loading the fashion MNIST dataset. Keras has a number of functions \n",
    "# to load popular datasets in `keras.datasets`. The dataset is already split for \n",
    "# you between a training set and a test set, but it can be useful to split \n",
    "# the training set further to have a validation set.\n",
    "\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The training set contains 60,000 grayscale images, each 28x28 pixels.\n",
    "\n",
    "\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each pixel intensity is represented as a byte (0 to 255).\n",
    "\n",
    "\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the full training set into a validation set and a (smaller, last 5000) \n",
    "# training set. We also scale the pixel intensities down to the 0-1 range \n",
    "# and convert them to floats, by dividing by 255. \n",
    "#\n",
    "#Additionally, since we are going to train the neural network using Gradient Descent, \n",
    "# we must scale the input features.\n",
    "\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255. \n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
    "# color map.\n",
    "\n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The labels are the class IDs (represented as uint8), from 0 to 9.\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the corresponding class names.\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the first image in the training set is a coat.\n",
    "\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The validation set contains 5,000 images, and the test set contains 10,000 images.\n",
    "\n",
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure... fashion_mnist_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at a sample of the images in the dataset in 4x10 grid.\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let’s build the neural network! Here is a classification MLP with two hidden layers.\n",
    "#\n",
    "# The first layer and add it to the model. It is a Flatten layer whose role is to \n",
    "# convert each input image into a 1D array, if it receives input data X , \n",
    "# it computes X.reshape(-1, 1) \n",
    "#\n",
    "# Next we add a Dense hidden layer with 300 neurons. It will use the ReLU activation \n",
    "# function.\n",
    "#\n",
    "# Then we add a second Dense hidden layer with 100 neurons, also using the ReLU \n",
    "# activation function.\n",
    "#\n",
    "# Finally, we add a Dense output layer with 10 neurons (one per class), using the \n",
    "# softmax activation function (because the classes are exclusive).\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of adding the layers one by one as we just did, you can pass a list\n",
    "# of layers when creating the Sequential model.\n",
    "#\n",
    "# The shape of the weight matrix depends on the number of inputs. This is why it is\n",
    "# recommended to specify the input_shape when creating the first layer in a\n",
    "# Sequential model. However, if you do not specify the input shape, it’s OK: Keras\n",
    "# will simply wait until it knows the input shape before it actually builds the model.\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x7fcd4c1295e0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fcd4f3aa760>,\n",
       " <keras.layers.core.dense.Dense at 0x7fcd4f3aa9d0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fcd4f3aaac0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,231\n",
      "Trainable params: 1,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense layers often have a lot of parameters. For example, the\n",
    "# first hidden layer has 784 × 300 connection weights, plus 300 bias terms,\n",
    "# which adds up to 235,500 parameters! This gives the model quite a lot of\n",
    "# flexibility to fit the training data, but it also means that the model runs the\n",
    "# risk of overfitting, especially when you do not have a lot of training data.\n",
    "#\n",
    "# Complex model has a risk to overfit!\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"resource/my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06111916, -0.04079123, -0.06318589, ...,  0.06584536,\n",
       "         0.05508354,  0.0097732 ],\n",
       "       [-0.03781921,  0.046078  ,  0.06775023, ..., -0.05698601,\n",
       "         0.05241117,  0.02067833],\n",
       "       [-0.03054678,  0.02646337, -0.03431542, ...,  0.04846076,\n",
       "         0.01414314,  0.01600082],\n",
       "       ...,\n",
       "       [ 0.04511474, -0.00856753,  0.04326578, ...,  0.02681568,\n",
       "        -0.06220669,  0.02591295],\n",
       "       [-0.027183  ,  0.02078319, -0.0145184 , ...,  0.04612534,\n",
       "         0.01242442,  0.05021076],\n",
       "       [-0.01368167,  0.05500107, -0.06967793, ...,  0.03485298,\n",
       "         0.04437702, -0.03601008]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"sparse_categorical_crossentropy\" loss because we have sparse\n",
    "# labels (i.e., for each instance, there is just a target class index, from 0 to 9\n",
    "# in this case), and the classes are exclusive. If instead we had one target\n",
    "# probability per class for each instance (such as one-hot vectors, \n",
    "# e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we\n",
    "# would need to use the \"categorical_crossentropy\" loss instead. If we\n",
    "# were doing binary classification (with one or more binary labels), then we\n",
    "# would use the \"sigmoid\" (i.e., logistic) activation function in the output\n",
    "# layer instead of the \"softmax\" activation function, and we would use the\n",
    "# \"binary_crossentropy\" loss.\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7179 - accuracy: 0.7653 - val_loss: 0.5267 - val_accuracy: 0.8194\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4888 - accuracy: 0.8297 - val_loss: 0.4369 - val_accuracy: 0.8498\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4428 - accuracy: 0.8434 - val_loss: 0.5497 - val_accuracy: 0.7920\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4162 - accuracy: 0.8557 - val_loss: 0.3959 - val_accuracy: 0.8642\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3977 - accuracy: 0.8611 - val_loss: 0.3819 - val_accuracy: 0.8670\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3790 - accuracy: 0.8668 - val_loss: 0.3764 - val_accuracy: 0.8740\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3670 - accuracy: 0.8707 - val_loss: 0.3686 - val_accuracy: 0.8716\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3557 - accuracy: 0.8745 - val_loss: 0.3865 - val_accuracy: 0.8634\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3452 - accuracy: 0.8785 - val_loss: 0.3607 - val_accuracy: 0.8704\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3360 - accuracy: 0.8807 - val_loss: 0.3551 - val_accuracy: 0.8724\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3277 - accuracy: 0.8837 - val_loss: 0.3503 - val_accuracy: 0.8770\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3186 - accuracy: 0.8869 - val_loss: 0.3388 - val_accuracy: 0.8784\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3119 - accuracy: 0.8892 - val_loss: 0.3322 - val_accuracy: 0.8842\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3057 - accuracy: 0.8905 - val_loss: 0.3515 - val_accuracy: 0.8734\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2978 - accuracy: 0.8935 - val_loss: 0.3306 - val_accuracy: 0.8810\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2927 - accuracy: 0.8952 - val_loss: 0.3141 - val_accuracy: 0.8874\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2868 - accuracy: 0.8967 - val_loss: 0.3655 - val_accuracy: 0.8686\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2808 - accuracy: 0.8991 - val_loss: 0.3258 - val_accuracy: 0.8846\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2755 - accuracy: 0.9016 - val_loss: 0.3157 - val_accuracy: 0.8876\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2701 - accuracy: 0.9032 - val_loss: 0.3330 - val_accuracy: 0.8786\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2658 - accuracy: 0.9047 - val_loss: 0.3062 - val_accuracy: 0.8914\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2602 - accuracy: 0.9062 - val_loss: 0.3010 - val_accuracy: 0.8898\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2559 - accuracy: 0.9071 - val_loss: 0.3081 - val_accuracy: 0.8890\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2517 - accuracy: 0.9086 - val_loss: 0.3063 - val_accuracy: 0.8894\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2470 - accuracy: 0.9101 - val_loss: 0.3035 - val_accuracy: 0.8908\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2423 - accuracy: 0.9123 - val_loss: 0.3116 - val_accuracy: 0.8886\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2393 - accuracy: 0.9143 - val_loss: 0.3033 - val_accuracy: 0.8884\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2354 - accuracy: 0.9146 - val_loss: 0.3050 - val_accuracy: 0.8870\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2313 - accuracy: 0.9160 - val_loss: 0.3170 - val_accuracy: 0.8834\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2277 - accuracy: 0.9178 - val_loss: 0.3201 - val_accuracy: 0.8840\n"
     ]
    }
   ],
   "source": [
    "# We pass it the input features ( X_train ) and the target classes ( y_train ),\n",
    "# as well as the number of epochs to train (or else it would default to just 1,\n",
    "# which would definitely not be enough to converge to a good solution). We\n",
    "# also pass a validation set (this is optional). Keras will measure the loss and\n",
    "# the extra metrics on this set at the end of each epoch, which is very useful\n",
    "# to see how well the model really performs. If the performance on the\n",
    "# training set is much better than on the validation set, your model is\n",
    "# probably overfitting the training set (or there is a bug, such as a data\n",
    "# mismatch between the training set and the validation set).\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure... keras_learning_curves_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can see that both the training accuracy and the validation accuracy\n",
    "# steadily increase during training, while the training loss and the validation\n",
    "# loss decrease. Good! Moreover, the validation curves are close to the\n",
    "# training curves, which means that there is not too much overfitting.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34585803747177124, 0.8784000277519226]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is common to get slightly lower performance on the test set than on the \n",
    "# validation set, because the hyperparameters are tuned on the validation set, \n",
    "# not the test set.\n",
    "# Remember to resist the temptation to tweak the hyperparameters on\n",
    "# the test set, or else your estimate of the generalization error will be too optimistic.\n",
    "\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.97],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.argmax gives teh max in an array\n",
    "\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure... fashion_mnist_images_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Regression MLP (_Multilayer Perceptron_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression means predicting a value. MLPs can be used for regression tasks. \n",
    "# If you want to predict a single value (e.g., the price of a house, given many \n",
    "# of its features), then you just need a single output neuron: its output is the \n",
    "# predicted value.\n",
    "#\n",
    "# Let's load, split and scale the California housing \n",
    "# dataset (the original one).\n",
    "# This dataset is simpler than the one used ealier, since it contains only\n",
    "# numerical features (there is no ocean_proximity feature), and there is no missing value.\n",
    "#\n",
    "# Difference between fit_transform() and transform()\n",
    "# Data standardization is the process of rescaling the attributes so that they have mean as 0 and variance as 1.\n",
    "# The fit method is calculating the mean and variance of each of the features present in our data. \n",
    "# The transform method is transforming all the features using the respective mean and variance.\n",
    "# The model learns on the tarin data and calculates the mean and variance but the model should not learn about \n",
    "# the test data, and hence just transform().\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8727 - val_loss: 2.5817\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7898 - val_loss: 1.3720\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6963 - val_loss: 0.8318\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6456 - val_loss: 0.6746\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6070 - val_loss: 0.5807\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5745 - val_loss: 0.5435\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5492 - val_loss: 0.5152\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 0.4956\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5105 - val_loss: 0.4795\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4961 - val_loss: 0.4655\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4844 - val_loss: 0.4525\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4744 - val_loss: 0.4424\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4661 - val_loss: 0.4345\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4592 - val_loss: 0.4287\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4530 - val_loss: 0.4244\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4213\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4432 - val_loss: 0.4202\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4396 - val_loss: 0.4195\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4355 - val_loss: 0.4174\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4241\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4277\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "# Using the Sequential API to build, train, evaluate, and use a regression\n",
    "# MLP to make predictions is quite similar to what we did for classification.\n",
    "# The main differences are the fact that the output layer has a single neuron\n",
    "# (since we only want to predict a single value) and uses no activation\n",
    "# function, and the loss function is the mean squared error. Since the dataset\n",
    "# is quite noisy, we just use a single hidden layer with fewer neurons than\n",
    "# before, to avoid overfitting.\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66558814],\n",
       "       [1.6160161 ],\n",
       "       [3.3775256 ]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Complex models using the functional API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all neural network models are simply sequential. Some may have complex topologies. \n",
    "# Some may have multiple inputs and/or multiple outputs. For example, \n",
    "# a Wide & Deep neural network connects all or part of the inputs directly \n",
    "# to the output layer.\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30)           930         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8601 - val_loss: 0.9694\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6393 - val_loss: 0.7612\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5990 - val_loss: 0.5480\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5657 - val_loss: 0.5375\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5455 - val_loss: 0.5433\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5247 - val_loss: 0.4913\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5112 - val_loss: 0.4790\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4978 - val_loss: 0.4850\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.4510\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4740 - val_loss: 0.4538\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4653 - val_loss: 0.5568\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4566 - val_loss: 0.4539\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4496 - val_loss: 0.4174\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4124\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4363 - val_loss: 0.4062\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4311 - val_loss: 0.4017\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4173\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4222 - val_loss: 0.4252\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4171 - val_loss: 0.3881\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 0.4153\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4118\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to send different subsets of input features through the wide or \n",
    "# deep paths? We will send 5 features (features 0 to 4), and 6 through the deep path \n",
    "# (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4).\n",
    "\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1495 - val_loss: 2.3704\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7831 - val_loss: 0.8455\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6779 - val_loss: 0.6342\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6255 - val_loss: 0.5815\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5890 - val_loss: 0.5471\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5603 - val_loss: 0.5218\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5377 - val_loss: 0.4999\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.4800\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5038 - val_loss: 0.4657\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4912 - val_loss: 0.4544\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4809 - val_loss: 0.4497\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4725 - val_loss: 0.4433\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4655 - val_loss: 0.4448\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4393\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4544 - val_loss: 0.4389\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4499 - val_loss: 0.4384\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4455 - val_loss: 0.4391\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4416 - val_loss: 0.4371\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4386\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4348 - val_loss: 0.4559\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4271\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcd4f5284c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# Each output will need its own loss function. Therefore, when we compile\n",
    "# the model, we should pass a list of losses.\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many use cases in which you may want to have multiple outputs.\n",
    "# \n",
    "# Object detection task, classification and adding a bounding box.\n",
    "# \n",
    "# Similarly, you may have multiple independent tasks based on the same data. Sure, \n",
    "# you could train one neural network per task, but in many cases you will get better \n",
    "# results on all tasks by training a single neural network with one output per task. \n",
    "# This is because the neural network can learn features in the data that are useful\n",
    "# across tasks. For example, you could perform multitask classification on pictures \n",
    "# of faces, using one output to classify the person’s facial expression (smiling, \n",
    "# surprised, etc.) and another output to identify whether they are wearing glasses or not.\n",
    "#\n",
    "# Another use case is as a regularization technique (i.e., a training constraint \n",
    "# whose objective is to reduce overfitting and thus improve the model’s ability to \n",
    "# generalize). For example, you may want to add some auxiliary outputs in a neural network\n",
    "# architecture to ensure that the underlying part of the network learns something \n",
    "# useful on its own, without relying on the rest of the network.\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again passing the loss functions list \n",
    "\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 3.1446 - main_output_loss: 2.9115 - aux_output_loss: 5.2424 - val_loss: 2.0658 - val_main_output_loss: 1.7803 - val_aux_output_loss: 4.6356\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1318 - main_output_loss: 0.8143 - aux_output_loss: 3.9897 - val_loss: 1.0735 - val_main_output_loss: 0.7052 - val_aux_output_loss: 4.3888\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8892 - main_output_loss: 0.6589 - aux_output_loss: 2.9623 - val_loss: 1.0215 - val_main_output_loss: 0.6270 - val_aux_output_loss: 4.5715\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7833 - main_output_loss: 0.6136 - aux_output_loss: 2.3106 - val_loss: 1.0204 - val_main_output_loss: 0.5821 - val_aux_output_loss: 4.9653\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7182 - main_output_loss: 0.5867 - aux_output_loss: 1.9019 - val_loss: 0.9856 - val_main_output_loss: 0.5492 - val_aux_output_loss: 4.9133\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6715 - main_output_loss: 0.5626 - aux_output_loss: 1.6514 - val_loss: 0.9772 - val_main_output_loss: 0.5492 - val_aux_output_loss: 4.8287\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6376 - main_output_loss: 0.5428 - aux_output_loss: 1.4904 - val_loss: 0.9699 - val_main_output_loss: 0.5781 - val_aux_output_loss: 4.4962\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6111 - main_output_loss: 0.5255 - aux_output_loss: 1.3815 - val_loss: 0.8647 - val_main_output_loss: 0.5101 - val_aux_output_loss: 4.0562\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5889 - main_output_loss: 0.5092 - aux_output_loss: 1.3057 - val_loss: 0.8118 - val_main_output_loss: 0.4996 - val_aux_output_loss: 3.6217\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5705 - main_output_loss: 0.4954 - aux_output_loss: 1.2465 - val_loss: 0.7690 - val_main_output_loss: 0.5012 - val_aux_output_loss: 3.1791\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5550 - main_output_loss: 0.4836 - aux_output_loss: 1.1980 - val_loss: 0.7124 - val_main_output_loss: 0.4568 - val_aux_output_loss: 3.0128\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5417 - main_output_loss: 0.4731 - aux_output_loss: 1.1585 - val_loss: 0.6974 - val_main_output_loss: 0.4788 - val_aux_output_loss: 2.6653\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5302 - main_output_loss: 0.4645 - aux_output_loss: 1.1214 - val_loss: 0.6538 - val_main_output_loss: 0.4498 - val_aux_output_loss: 2.4902\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5200 - main_output_loss: 0.4569 - aux_output_loss: 1.0883 - val_loss: 0.6283 - val_main_output_loss: 0.4462 - val_aux_output_loss: 2.2680\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5114 - main_output_loss: 0.4507 - aux_output_loss: 1.0572 - val_loss: 0.5964 - val_main_output_loss: 0.4231 - val_aux_output_loss: 2.1569\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - main_output_loss: 0.4458 - aux_output_loss: 1.0316 - val_loss: 0.5815 - val_main_output_loss: 0.4295 - val_aux_output_loss: 1.9493\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4983 - main_output_loss: 0.4419 - aux_output_loss: 1.0062 - val_loss: 0.5584 - val_main_output_loss: 0.4138 - val_aux_output_loss: 1.8593\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4932 - main_output_loss: 0.4387 - aux_output_loss: 0.9835 - val_loss: 0.5416 - val_main_output_loss: 0.4056 - val_aux_output_loss: 1.7660\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4883 - main_output_loss: 0.4357 - aux_output_loss: 0.9624 - val_loss: 0.5317 - val_main_output_loss: 0.4120 - val_aux_output_loss: 1.6086\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4842 - main_output_loss: 0.4334 - aux_output_loss: 0.9417 - val_loss: 0.5181 - val_main_output_loss: 0.3982 - val_aux_output_loss: 1.5978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4763 - main_output_loss: 0.4276 - aux_output_loss: 0.9149\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcd4f2628b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Subclassing API to build dynamic models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sequential API is static and graph of layers. But thats not always the case.\n",
    "# Some models involve loops, varying shapes, conditional branching, and other \n",
    "# dynamic behaviors. For such cases, or simply if you prefer a more imperative \n",
    "# programming style, the Subclassing API is for you.\n",
    "#\n",
    "# Simply subclass the Model class, create the layers you need in the\n",
    "# constructor, and use them to perform the computations you want in the call() method.\n",
    "#\n",
    "# The big difference is that you can do pretty much anything you want in the \n",
    "# call() method: for loops, if statements, low-level TensorFlow operations.\n",
    "\n",
    "\n",
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.5411 - output_1_loss: 2.3619 - output_2_loss: 4.1541 - val_loss: 2.2150 - val_output_1_loss: 1.8127 - val_output_2_loss: 5.8360\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0108 - output_1_loss: 0.8153 - output_2_loss: 2.7704 - val_loss: 1.3208 - val_output_1_loss: 0.6836 - val_output_2_loss: 7.0551\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8069 - output_1_loss: 0.6596 - output_2_loss: 2.1328 - val_loss: 1.2913 - val_output_1_loss: 0.6380 - val_output_2_loss: 7.1711\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7339 - output_1_loss: 0.6101 - output_2_loss: 1.8476 - val_loss: 1.1776 - val_output_1_loss: 0.5849 - val_output_2_loss: 6.5126\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6902 - output_1_loss: 0.5789 - output_2_loss: 1.6920 - val_loss: 1.0437 - val_output_1_loss: 0.5467 - val_output_2_loss: 5.5162\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6571 - output_1_loss: 0.5534 - output_2_loss: 1.5899 - val_loss: 0.9373 - val_output_1_loss: 0.5320 - val_output_2_loss: 4.5846\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6314 - output_1_loss: 0.5335 - output_2_loss: 1.5121 - val_loss: 0.8372 - val_output_1_loss: 0.5090 - val_output_2_loss: 3.7907\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6101 - output_1_loss: 0.5164 - output_2_loss: 1.4526 - val_loss: 0.7475 - val_output_1_loss: 0.4814 - val_output_2_loss: 3.1429\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5922 - output_1_loss: 0.5021 - output_2_loss: 1.4032 - val_loss: 0.6816 - val_output_1_loss: 0.4631 - val_output_2_loss: 2.6478\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5777 - output_1_loss: 0.4907 - output_2_loss: 1.3614 - val_loss: 0.6340 - val_output_1_loss: 0.4555 - val_output_2_loss: 2.2401\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5714 - output_1_loss: 0.4871 - output_2_loss: 1.3309\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Saving and restoring a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.4877 - val_loss: 1.1324\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8894 - val_loss: 0.8491\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6983 - val_loss: 0.7324\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6437 - val_loss: 0.6097\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6109 - val_loss: 0.5584\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5831 - val_loss: 0.5389\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5595 - val_loss: 0.5276\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.4929\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5206 - val_loss: 0.4748\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5047 - val_loss: 0.4631\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4889\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras will use the HDF5 format to save both the model’s architecture\n",
    "# (including every layer’s hyperparameters) and the values of all the model\n",
    "# parameters for every layer (e.g., connection weights and biases). It also\n",
    "# saves the optimizer (including its hyperparameters and any state it may have).\n",
    "#\n",
    "# This will work when using the Sequential API or the Functional API, but\n",
    "# unfortunately not when using model subclassing. You can use save_weights() and\n",
    "# load_weights() to at least save and restore the model parameters, but you will\n",
    "# need to save and restore everything else yourself.\n",
    "\n",
    "\n",
    "model.save(\"trained_models/my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8714886],\n",
       "       [1.4894865],\n",
       "       [3.1455941]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"trained_models/my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fcd540f1220>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"trained_models/my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Using Callbacks during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is quite common to tarin for long hours, especially when training on large datasets. \n",
    "# In this case, you should not only save your model at the end of training, \n",
    "# but also save checkpoints at regular intervals during training, to avoid \n",
    "# losing everything if your computer crashes. But how can you tell the fit() \n",
    "# method to save checkpoints? Use callbacks.\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5038 - val_loss: 0.4620\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4878 - val_loss: 0.4496\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4736 - val_loss: 0.4351\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4599 - val_loss: 0.4423\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4523 - val_loss: 0.4155\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4412 - val_loss: 0.4219\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4366 - val_loss: 0.4020\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4302 - val_loss: 0.3968\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.4111\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.3913\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4288\n"
     ]
    }
   ],
   "source": [
    "# The fit() method accepts a callbacks argument that lets you specify a\n",
    "# list of objects that Keras will call at the start and end of training, at the\n",
    "# start and end of each epoch, and even before and after processing each\n",
    "# batch. For example, the ModelCheckpoint callback saves checkpoints of\n",
    "# your model at regular intervals during training, by default at the end of each epoch.\n",
    "#\n",
    "# Moreover, if you use a validation set during training, you can set\n",
    "# save_best_only=True when creating the ModelCheckpoint . In this case, \n",
    "# it will only save your model when its performance on the validation set is\n",
    "# the best so far. This is also called Early Stopping.\n",
    "#\n",
    "# Another way to implement early stopping is to simply use the\n",
    "# EarlyStopping callback. It will interrupt training when it measures no progress on \n",
    "# the validation set for a number of epochs (defined by the patience argument), \n",
    "# and it will optionally roll back to the best model.\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"trained_models/my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"trained_models/my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4172 - val_loss: 0.3915\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4136 - val_loss: 0.4418\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.4008\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4142\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.3776\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4251\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.3706\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.3693\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3933 - val_loss: 0.3884\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3917 - val_loss: 0.3703\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3616\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3875 - val_loss: 0.4280\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.3667\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.3646\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.3597\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3548\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.4172\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3785 - val_loss: 0.3628\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.3655\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3752 - val_loss: 0.4105\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.3604\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.4484\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.3538\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.4081\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3681 - val_loss: 0.3882\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3674 - val_loss: 0.4087\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.3437\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.3969\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.3582\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.4053\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3442\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.4034\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.3481\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3557\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.4097\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3371\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.3802\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3415\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3561 - val_loss: 0.3640\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3386\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3964\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3425\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3531 - val_loss: 0.3782\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3702\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3437\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3462\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3572\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need extra control, you can easily write your own custom callbacks.\n",
    "# As an example of how to do that, the following custom callback will display the ratio \n",
    "# between the validation loss and the training loss during training \n",
    "# (e.g., to detect overfitting).\n",
    "\n",
    "\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/363 [============================>.] - ETA: 0s - loss: 0.3572\n",
      "val/train: 1.04\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.3730\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### TensorBoard for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard is a great interactive visualization tool that you can use to\n",
    "# view the learning curves during training, compare learning curves between\n",
    "# multiple runs, visualize the computation graph, analyze training statistics,\n",
    "# view images generated by your model.\n",
    "\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"logs/my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/my_logs/run_2023_03_22-17_51_37'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.0990 - val_loss: 1.7729\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7886 - val_loss: 0.9155\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6865 - val_loss: 0.6119\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6340 - val_loss: 0.5900\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5990 - val_loss: 0.5525\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5689 - val_loss: 0.5262\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5434 - val_loss: 0.4994\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5198 - val_loss: 0.4745\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4988 - val_loss: 0.4553\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4803 - val_loss: 0.4407\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4648 - val_loss: 0.4348\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4315\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4416 - val_loss: 0.4351\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4381\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4414\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4483\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4147 - val_loss: 0.4573\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4106 - val_loss: 0.4651\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.4710\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4865\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4001 - val_loss: 0.4941\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.4960\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3947 - val_loss: 0.4693\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3924 - val_loss: 0.4765\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3900 - val_loss: 0.4803\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.4849\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 0.4650\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3844 - val_loss: 0.4709\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.4617\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3809 - val_loss: 0.4736\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook's directory, then type:\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "```\n",
    "\n",
    "You can then open your web browser to [localhost:6006](http://localhost:6006) and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.\n",
    "\n",
    "Alternatively, you can load TensorBoard's Jupyter extension and run it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a00bece5c4779f94\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a00bece5c4779f94\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/my_logs/run_2023_03_22-17_54_54'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5447 - val_loss: 20.1916\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how TensorBoard now sees two runs, and you can compare the learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the other available logging options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "\n",
    " - For many problems, you can begin with a single hidden layer and get reasonable results. An MLP with just one hidden layer can theoretically model even the most complex functions, provided it has enough neurons. \n",
    " - Reusing the previously learned model (weights and biases) so that the network wil lnot have to learn from scratch all the lower-level structures and it will only have to learn the higher-level structures is called _transfer learning_.\n",
    " - The number of neurons in the input and output layers is determined by the type of input and output your task requires. As for the hidden layers, it used to be common to size them to form a pyramid, with fewer and fewer neurons at each layer—the rationale being that many low-level features can coalesce into far fewer high-level features.\n",
    " - The learning rate is arguably the most important hyperparameter. In general, the optimal learning rate is about half of the maximum learning rate (i.e., the learning rate above which the training algorithm diverges).\n",
    " - Choosing a better optimizer than plain old Mini-batch Gradient Descent (and tuning its hyperparameters) is also quite important.\n",
    " - The batch size can have a significant impact on your model’s performance and training time. The main benefit of using large batch sizes is that hardware accelerators like GPUs can process them efficiently, so the training algorithm will see more instances per second. Therefore, many researchers and practitioners recommend using the largest batch size that can fit in GPU RAM.\n",
    " - In general, the ReLU activation function will be a good default for all hidden layers. For the output layer, it really depends on your task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212852/1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0280 - val_loss: 5.6545\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6264 - val_loss: 7.4106\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5570 - val_loss: 6.7768\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4980 - val_loss: 4.9808\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4672 - val_loss: 2.7542\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4464 - val_loss: 1.8410\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 0.8282\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.4425\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4069 - val_loss: 0.3813\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4015 - val_loss: 0.4111\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4829\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3948 - val_loss: 0.5859\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3943 - val_loss: 0.3946\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3907 - val_loss: 0.3593\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.3607\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3842 - val_loss: 0.3576\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.3832\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.3535\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.3502\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3758 - val_loss: 0.3845\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.5892\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 1.4566\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3733 - val_loss: 1.0398\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3771 - val_loss: 0.5369\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.7183\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 1.3320\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3704 - val_loss: 1.1792\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 1.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd54808a60>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3630\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5845 - val_loss: 1.8168\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2517 - val_loss: 0.8650\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7721 - val_loss: 0.6747\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6522 - val_loss: 0.6237\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 0.6061\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 0.8091\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5888 - val_loss: 0.7575\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5810 - val_loss: 0.7742\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5768 - val_loss: 0.5837\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5672 - val_loss: 0.7882\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 0.8007\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - val_loss: 0.5489\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5533 - val_loss: 0.8488\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5529 - val_loss: 0.9036\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5537 - val_loss: 0.5977\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.7422\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5455 - val_loss: 0.7568\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.8379\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 0.8614\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 0.8353\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.5702\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5350 - val_loss: 0.7764\n",
      "121/121 [==============================] - 0s 970us/step - loss: 0.5347\n",
      "[CV] END learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15; total time=   9.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7700 - val_loss: 1.6765\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1715 - val_loss: 1.2520\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6903 - val_loss: 2.0789\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5860 - val_loss: 3.2817\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 4.6459\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 6.0712\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 7.4557\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 8.8125\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 10.0712\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 11.1049\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 12.1978\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 13.1744\n",
      "121/121 [==============================] - 0s 955us/step - loss: 0.8377\n",
      "[CV] END learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15; total time=   5.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3638 - val_loss: 1.7142\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2672 - val_loss: 0.8913\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8090 - val_loss: 0.7186\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7021 - val_loss: 0.9172\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6703 - val_loss: 0.6189\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6518 - val_loss: 0.6964\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6381 - val_loss: 0.7140\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.9540\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.7207\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.5687\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5988 - val_loss: 0.8947\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5968 - val_loss: 0.6194\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5871 - val_loss: 0.5538\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 0.6558\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5782 - val_loss: 0.5674\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5703 - val_loss: 0.7892\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5708 - val_loss: 0.5923\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5656 - val_loss: 0.5711\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 0.8649\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.6324\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5566 - val_loss: 0.6245\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5537 - val_loss: 0.6546\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5534 - val_loss: 0.5289\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 0.5754\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.5528\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.5054\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 0.8491\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.5947\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 0.7642\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 0.6136\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.6924\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 0.7736\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 0.7637\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.8148\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5377 - val_loss: 0.8028\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 0.5241\n",
      "121/121 [==============================] - 0s 949us/step - loss: 0.5349\n",
      "[CV] END learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15; total time=  15.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5770 - val_loss: 249.1148\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.6634 - val_loss: 730.4564\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7.6486 - val_loss: 3248.2136\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 20.1633 - val_loss: 11634.4668\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 79.0994 - val_loss: 47741.3125\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 961.3315 - val_loss: 186993.4844\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2001.1121 - val_loss: 738082.8750\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 14289.1621 - val_loss: 2914019.5000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 36323.4766 - val_loss: 11552792.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 254893.8594 - val_loss: 48039296.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 642937.5000 - val_loss: 188269216.0000\n",
      "121/121 [==============================] - 0s 998us/step - loss: 500044.2812\n",
      "[CV] END learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21; total time=   5.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2176 - val_loss: 9.3008\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 15.0596\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 18.8008\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 19.6500\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 19.9958\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5089 - val_loss: 20.1459\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 19.7833\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5054 - val_loss: 20.5266\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 19.9596\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5034 - val_loss: 16.9851\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5038 - val_loss: 19.1023\n",
      "121/121 [==============================] - 0s 968us/step - loss: 0.9526\n",
      "[CV] END learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21; total time=   4.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4630 - val_loss: 6.6024\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5885 - val_loss: 0.8995\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6541 - val_loss: 46.8783\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3980 - val_loss: 109.9619\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9823 - val_loss: 522.6544\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.9578 - val_loss: 814.7909\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.7904 - val_loss: 1754.4327\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 33.1112 - val_loss: 3568.1489\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 36.0091 - val_loss: 7118.1206\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 18.4175 - val_loss: 12261.0146\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 326.7600 - val_loss: 23310.1172\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 140.4865 - val_loss: 43885.5430\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 46.7238\n",
      "[CV] END learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21; total time=   5.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6374 - val_loss: 2.2489\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0237 - val_loss: 0.9807\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7956 - val_loss: 0.7345\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7274 - val_loss: 0.6693\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6892 - val_loss: 0.6351\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6604 - val_loss: 0.6098\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6359 - val_loss: 0.5915\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6143 - val_loss: 0.5685\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5946 - val_loss: 0.5472\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5761 - val_loss: 0.5313\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5593 - val_loss: 0.5179\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5441 - val_loss: 0.5006\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5296 - val_loss: 0.4895\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5164 - val_loss: 0.4763\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5043 - val_loss: 0.4631\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4928 - val_loss: 0.4534\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4826 - val_loss: 0.4437\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4731 - val_loss: 0.4354\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4643 - val_loss: 0.4288\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4565 - val_loss: 0.4210\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4492 - val_loss: 0.4180\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4424 - val_loss: 0.4117\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4364 - val_loss: 0.4069\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.4007\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.4014\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4212 - val_loss: 0.4000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.3955\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.3994\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4095 - val_loss: 0.3971\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.3921\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.3864\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4006 - val_loss: 0.3875\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.3903\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3956 - val_loss: 0.3917\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3934 - val_loss: 0.3866\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3913 - val_loss: 0.3897\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3893 - val_loss: 0.3835\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3875 - val_loss: 0.3891\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3857 - val_loss: 0.3834\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3841 - val_loss: 0.3912\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.3873\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3809 - val_loss: 0.3829\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.3790\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.3929\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.3872\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.3837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3916\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.3872\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3717 - val_loss: 0.3849\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.3906\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3694 - val_loss: 0.3843\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.3861\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.3856\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3802\n",
      "[CV] END learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87; total time=  30.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.5816 - val_loss: 22.3278\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9448 - val_loss: 21.0806\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7533 - val_loss: 15.3754\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6930 - val_loss: 10.8934\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6567 - val_loss: 7.7572\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6281 - val_loss: 5.6783\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6033 - val_loss: 4.0810\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5811 - val_loss: 2.9096\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5612 - val_loss: 2.1352\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5434 - val_loss: 1.5641\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.2342\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5128 - val_loss: 0.9245\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5001 - val_loss: 0.7425\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.6502\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5542\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4690 - val_loss: 0.5076\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.4641\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4535 - val_loss: 0.4398\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4466 - val_loss: 0.4210\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4133\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4069\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.4031\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.3992\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4220 - val_loss: 0.3956\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.3923\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.3890\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4115 - val_loss: 0.3863\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4084 - val_loss: 0.3832\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.3860\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4031 - val_loss: 0.3823\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4003 - val_loss: 0.3789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.3817\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3957 - val_loss: 0.3828\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.3911\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4004\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3949\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.4093\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.4214\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3846 - val_loss: 0.4301\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3833 - val_loss: 0.4493\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.4704\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3919\n",
      "[CV] END learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87; total time=  22.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1569 - val_loss: 2.7371\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1154 - val_loss: 1.3470\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7711 - val_loss: 0.7529\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6876 - val_loss: 0.6414\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6526 - val_loss: 0.6119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.5895\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6110 - val_loss: 0.5735\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5950 - val_loss: 0.5674\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5807 - val_loss: 0.5442\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5543 - val_loss: 0.5187\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5426 - val_loss: 0.5063\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5316 - val_loss: 0.4959\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5212 - val_loss: 0.4876\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5115 - val_loss: 0.4789\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5025 - val_loss: 0.4678\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4940 - val_loss: 0.4605\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4862 - val_loss: 0.4528\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4791 - val_loss: 0.4460\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.4400\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4663 - val_loss: 0.4342\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4605 - val_loss: 0.4290\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4553 - val_loss: 0.4255\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.4269\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4458 - val_loss: 0.4166\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4132\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4374 - val_loss: 0.4085\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.4074\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4301 - val_loss: 0.4094\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4020\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4239 - val_loss: 0.3968\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4006\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.3940\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4156 - val_loss: 0.4053\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4134 - val_loss: 0.3947\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.3913\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.3907\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.3946\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4047 - val_loss: 0.3888\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4028 - val_loss: 0.3866\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.4021\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.3943\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3977 - val_loss: 0.3809\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3965 - val_loss: 0.3881\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.3892\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.3836\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.3771\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.3771\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.3870\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.3902\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.3852\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.3862\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.3788\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.3726\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.3748\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3828 - val_loss: 0.3784\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3847\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.3829\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.3856\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.3774\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3823\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3898\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.3785\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.3747\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3742\n",
      "[CV] END learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87; total time=  35.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7314 - val_loss: 4.1302\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5582 - val_loss: 2.0376\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1929 - val_loss: 1.2007\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9953 - val_loss: 0.9229\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8738 - val_loss: 0.8389\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8002 - val_loss: 0.8208\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7547 - val_loss: 0.8126\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7239 - val_loss: 0.7811\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7002 - val_loss: 0.7511\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6804 - val_loss: 0.7300\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6634 - val_loss: 0.7009\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6481 - val_loss: 0.6737\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6342 - val_loss: 0.6549\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6213 - val_loss: 0.6302\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6092 - val_loss: 0.6125\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5976 - val_loss: 0.5965\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5871 - val_loss: 0.5787\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5772 - val_loss: 0.5670\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5679 - val_loss: 0.5525\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5593 - val_loss: 0.5434\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5513 - val_loss: 0.5283\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5435 - val_loss: 0.5186\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5095\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.5028\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5229 - val_loss: 0.4929\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5166 - val_loss: 0.4846\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5108 - val_loss: 0.4783\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5051 - val_loss: 0.4718\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 0.4668\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4948 - val_loss: 0.4620\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4900 - val_loss: 0.4576\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4854 - val_loss: 0.4537\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4810 - val_loss: 0.4499\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4768 - val_loss: 0.4465\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4728 - val_loss: 0.4436\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4692 - val_loss: 0.4404\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4382\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4622 - val_loss: 0.4356\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4588 - val_loss: 0.4331\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4557 - val_loss: 0.4316\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4527 - val_loss: 0.4291\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4499 - val_loss: 0.4278\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4473 - val_loss: 0.4252\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4447 - val_loss: 0.4256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 0.4228\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4399 - val_loss: 0.4202\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4379 - val_loss: 0.4202\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4356 - val_loss: 0.4184\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4336 - val_loss: 0.4186\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4316 - val_loss: 0.4172\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4296 - val_loss: 0.4140\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.4157\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4163\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4243 - val_loss: 0.4130\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4225 - val_loss: 0.4138\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.4144\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4123\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4135\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4165 - val_loss: 0.4116\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4104\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4138 - val_loss: 0.4124\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.4106\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.4084\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4123\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.4125\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4105\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4063 - val_loss: 0.4088\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4112\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4091\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4062\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4022 - val_loss: 0.4106\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.4097\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4083\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3992 - val_loss: 0.4067\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4081\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3972 - val_loss: 0.4070\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3965 - val_loss: 0.4066\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4082\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3946 - val_loss: 0.4066\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.4035\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4075\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.4091\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3913 - val_loss: 0.4058\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3905 - val_loss: 0.4075\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.4026\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3887 - val_loss: 0.4082\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4033\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.3999\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.4017\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3859 - val_loss: 0.4028\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4005\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3846 - val_loss: 0.3991\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.3975\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.3952\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.3978\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.3995\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3811 - val_loss: 0.3931\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.3924\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3796 - val_loss: 0.4022\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.3949\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3944\n",
      "[CV] END learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24; total time= 1.0min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2327 - val_loss: 1.5135\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1490 - val_loss: 1.1431\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8746 - val_loss: 0.8790\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7729 - val_loss: 0.7508\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7156 - val_loss: 0.6912\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6797 - val_loss: 0.6738\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6551 - val_loss: 0.6786\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6365 - val_loss: 0.7066\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6212 - val_loss: 0.7272\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6083 - val_loss: 0.7617\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5967 - val_loss: 0.7829\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5862 - val_loss: 0.8256\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5768 - val_loss: 0.8600\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5681 - val_loss: 0.8671\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5598 - val_loss: 0.8971\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5520 - val_loss: 0.9160\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5704\n",
      "[CV] END learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24; total time=  11.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.1457 - val_loss: 4.3775\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1249 - val_loss: 4.1030\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5559 - val_loss: 3.1566\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2714 - val_loss: 2.4934\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0838 - val_loss: 1.9087\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9519 - val_loss: 1.5058\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8595 - val_loss: 1.2375\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7964 - val_loss: 1.0246\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7515 - val_loss: 0.8856\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7179 - val_loss: 0.7850\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6912 - val_loss: 0.7260\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6691 - val_loss: 0.6777\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6505 - val_loss: 0.6435\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6341 - val_loss: 0.6167\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6193 - val_loss: 0.5940\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6060 - val_loss: 0.5745\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5937 - val_loss: 0.5597\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5823 - val_loss: 0.5478\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5719 - val_loss: 0.5384\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5622 - val_loss: 0.5305\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5531 - val_loss: 0.5235\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5448 - val_loss: 0.5175\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5370 - val_loss: 0.5127\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5294 - val_loss: 0.5087\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5227 - val_loss: 0.5054\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5163 - val_loss: 0.5026\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 0.5000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5043 - val_loss: 0.4955\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4988 - val_loss: 0.4904\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 0.4857\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4891 - val_loss: 0.4807\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4846 - val_loss: 0.4746\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4803 - val_loss: 0.4693\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4763 - val_loss: 0.4640\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4726 - val_loss: 0.4592\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4689 - val_loss: 0.4541\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4655 - val_loss: 0.4493\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4622 - val_loss: 0.4449\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4591 - val_loss: 0.4409\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4561 - val_loss: 0.4371\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4531 - val_loss: 0.4336\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4507 - val_loss: 0.4299\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4481 - val_loss: 0.4266\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4458 - val_loss: 0.4235\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4434 - val_loss: 0.4207\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4411 - val_loss: 0.4181\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4390 - val_loss: 0.4157\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4371 - val_loss: 0.4135\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4351 - val_loss: 0.4115\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4333 - val_loss: 0.4097\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4313 - val_loss: 0.4081\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.4066\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4053\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4266 - val_loss: 0.4041\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4249 - val_loss: 0.4036\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4235 - val_loss: 0.4025\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4013\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4208 - val_loss: 0.4005\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4194 - val_loss: 0.3996\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.3989\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.3989\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4156 - val_loss: 0.3986\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.3979\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.3974\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4122 - val_loss: 0.3975\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4110 - val_loss: 0.3980\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4100 - val_loss: 0.3968\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4090 - val_loss: 0.3967\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.3970\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4069 - val_loss: 0.3964\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4059 - val_loss: 0.3960\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4050 - val_loss: 0.3964\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4038 - val_loss: 0.3958\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4031 - val_loss: 0.3966\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.3968\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 0.3960\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.3961\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.3960\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3988 - val_loss: 0.3963\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.3974\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3973 - val_loss: 0.3972\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.3966\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.3967\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3919\n",
      "[CV] END learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24; total time=  52.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3438 - val_loss: 18.3873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9609 - val_loss: 69.5530\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 123.7018\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8119 - val_loss: 358.8937\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7872 - val_loss: 695.6044\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 12.0761 - val_loss: 1535.4867\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 15.0184 - val_loss: 3519.3513\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 55.1735 - val_loss: 8042.1997\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 86.4202 - val_loss: 17943.4590\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 297.5990 - val_loss: 42877.1484\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 500.4661 - val_loss: 98334.4219\n",
      "121/121 [==============================] - 0s 991us/step - loss: 255.9070\n",
      "[CV] END learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2; total time=   5.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5114 - val_loss: 9.6811\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5564 - val_loss: 14.6509\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 18.0833\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 19.4402\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5171 - val_loss: 20.1362\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5125 - val_loss: 20.5174\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 20.4009\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 20.7779\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 20.4828\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 18.8103\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5033 - val_loss: 19.7095\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9695\n",
      "[CV] END learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2; total time=   5.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7986 - val_loss: 23.8988\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6542 - val_loss: 21.4703\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7826 - val_loss: 65.6712\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5046 - val_loss: 112.9161\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1520 - val_loss: 276.1356\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.5334 - val_loss: 340.3773\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1821 - val_loss: 528.6274\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8.0175 - val_loss: 829.3923\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9.0451 - val_loss: 1222.6149\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.4380 - val_loss: 1482.5400\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 29.0678 - val_loss: 2033.0704\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 14.1563 - val_loss: 2738.5757\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8209\n",
      "[CV] END learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2; total time=   5.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1371 - val_loss: 18.2367\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7600 - val_loss: 38.7040\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7817 - val_loss: 18.5923\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 11.4378\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4991 - val_loss: 1.7472\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.4734\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.4453\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4547\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4365\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4160\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4274\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.4109\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3740 - val_loss: 0.4066\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4011\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3982\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.4047\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.3944\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.3857\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3848\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3607 - val_loss: 0.3908\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.3801\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3758\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.4006\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.3757\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3862\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3603\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.3658\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.3641\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.3641\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 0.3560\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3514\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.3484\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3600\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3511\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3445\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3567\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3394\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3616\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.3408\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 0.3432\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3425\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3371 - val_loss: 0.3304\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3323\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3406\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3491 - val_loss: 0.3347\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.3376\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3357 - val_loss: 0.3440\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3376 - val_loss: 0.3471\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3191\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3328 - val_loss: 0.3535\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3312 - val_loss: 0.3589\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3362\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3767\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3277 - val_loss: 0.3310\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.3476\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3212\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3463\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.3291\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3261 - val_loss: 0.3175\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3241 - val_loss: 0.3233\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3317\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3213 - val_loss: 0.4049\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3234 - val_loss: 0.3158\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3217 - val_loss: 0.3413\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.3384\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.3143\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3745\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3186 - val_loss: 0.3289\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3175 - val_loss: 0.3987\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3185 - val_loss: 0.3129\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3164 - val_loss: 0.3384\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3156 - val_loss: 0.4222\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3176 - val_loss: 0.3268\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3173 - val_loss: 0.5170\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3177 - val_loss: 0.3133\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3361\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3155 - val_loss: 0.3136\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3140 - val_loss: 0.3472\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3143 - val_loss: 0.3354\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3120 - val_loss: 0.3428\n",
      "121/121 [==============================] - 0s 997us/step - loss: 0.3451\n",
      "[CV] END learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38; total time=  37.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9600 - val_loss: 1.0808\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.7892\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.7802\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.6533\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.4632\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.3832\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4363\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3993 - val_loss: 0.4782\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.7223\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3922 - val_loss: 0.6332\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.7136\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.7914\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.9044\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.9245\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 1.0075\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.9999\n",
      "121/121 [==============================] - 0s 930us/step - loss: 0.3956\n",
      "[CV] END learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38; total time=   7.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1066 - val_loss: 2.1076\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.4637\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 4.9038\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5824 - val_loss: 12.8705\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5300 - val_loss: 1.0530\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4476 - val_loss: 0.4910\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 0.4247\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.3931\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.3827\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 0.3775\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.3772\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.3783\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.3734\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.3790\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.3711\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.3769\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3678\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3645\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.3603\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 0.3633\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.3488\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3529\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3609\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3449\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3466\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.3546\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3471\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.3514\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.3451\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 0.3421\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3615 - val_loss: 0.3461\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.3465\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 0.3414\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.3392\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3565 - val_loss: 0.3345\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.3670\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.3489\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3541 - val_loss: 0.3446\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3372\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3324\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3421\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.3669\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.3343\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.3417\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3461\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.4245\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3312\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.3389\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3272\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 0.3393\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.3299\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.3626\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3325\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.3634\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3311\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3445\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3203\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3387 - val_loss: 0.3476\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.3438\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3236\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.3302\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3756\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3419 - val_loss: 0.3193\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.4619\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.3904\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.7593\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.8247\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 1.3626\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 1.2202\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.6310\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 0.3486\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3444 - val_loss: 0.3387\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.3209\n",
      "121/121 [==============================] - 0s 985us/step - loss: 0.3321\n",
      "[CV] END learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38; total time=  34.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.5102 - val_loss: 4.4847\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.0728 - val_loss: 5.1255\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2981 - val_loss: 4.4864\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0330 - val_loss: 3.2044\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8870 - val_loss: 2.1922\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7916 - val_loss: 1.7043\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7296 - val_loss: 1.4128\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6855 - val_loss: 1.2181\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6530 - val_loss: 1.0718\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6282 - val_loss: 0.9504\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6083 - val_loss: 0.8655\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5919 - val_loss: 0.8193\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5778 - val_loss: 0.7773\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5654 - val_loss: 0.7502\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5542 - val_loss: 0.7156\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.6889\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 0.6683\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5256 - val_loss: 0.6456\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5174 - val_loss: 0.6268\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5098 - val_loss: 0.6055\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5028 - val_loss: 0.5915\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4963 - val_loss: 0.5766\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4902 - val_loss: 0.5633\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4844 - val_loss: 0.5478\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4793 - val_loss: 0.5396\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4743 - val_loss: 0.5284\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4698 - val_loss: 0.5208\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4655 - val_loss: 0.5118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4616 - val_loss: 0.5057\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4579 - val_loss: 0.4978\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4544 - val_loss: 0.4909\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4511 - val_loss: 0.4866\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4480 - val_loss: 0.4814\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4450 - val_loss: 0.4757\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4423 - val_loss: 0.4710\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4396 - val_loss: 0.4657\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4373 - val_loss: 0.4629\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4350 - val_loss: 0.4591\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4328 - val_loss: 0.4560\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4307 - val_loss: 0.4540\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4287 - val_loss: 0.4520\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4269 - val_loss: 0.4498\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4252 - val_loss: 0.4459\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4234 - val_loss: 0.4456\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4218 - val_loss: 0.4430\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4201 - val_loss: 0.4391\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4386\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4173 - val_loss: 0.4371\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4159 - val_loss: 0.4372\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4146 - val_loss: 0.4343\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4318\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 0.4315\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4310\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4290\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4288\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.4277\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4062 - val_loss: 0.4273\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4268\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4042 - val_loss: 0.4261\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4030 - val_loss: 0.4235\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4024 - val_loss: 0.4244\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4247\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4218\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3996 - val_loss: 0.4227\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3987 - val_loss: 0.4230\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3979 - val_loss: 0.4219\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4198\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4200\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3954 - val_loss: 0.4178\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4160\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4166\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.4167\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.4148\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.4140\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4141\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3901 - val_loss: 0.4128\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3896 - val_loss: 0.4129\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3889 - val_loss: 0.4141\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3882 - val_loss: 0.4133\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3875 - val_loss: 0.4103\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.4122\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.4128\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4114\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.4129\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4100\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.4136\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.4113\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.4106\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.4112\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.4118\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3813 - val_loss: 0.4110\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3807 - val_loss: 0.4107\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.4101\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4095\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.4105\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3786 - val_loss: 0.4118\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4093\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.4073\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.4124\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.4085\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3928\n",
      "[CV] END learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21; total time= 1.0min\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.5457 - val_loss: 17.0275\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9595 - val_loss: 34.2164\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3761 - val_loss: 35.0399\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1439 - val_loss: 31.6026\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0062 - val_loss: 26.7959\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9171 - val_loss: 23.2929\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8577 - val_loss: 20.1828\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8173 - val_loss: 17.3998\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7876 - val_loss: 15.3547\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7642 - val_loss: 13.6475\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7449 - val_loss: 12.3859\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7277 - val_loss: 10.6872\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7124 - val_loss: 9.5117\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6983 - val_loss: 8.3737\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6851 - val_loss: 7.3035\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6726 - val_loss: 6.5639\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6609 - val_loss: 5.5853\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6496 - val_loss: 4.8943\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6389 - val_loss: 4.1877\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6287 - val_loss: 3.7358\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6191 - val_loss: 3.2480\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6098 - val_loss: 2.8279\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6010 - val_loss: 2.5140\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5927 - val_loss: 2.1269\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5847 - val_loss: 1.8439\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5771 - val_loss: 1.5839\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5698 - val_loss: 1.3941\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5628 - val_loss: 1.1864\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5560 - val_loss: 1.1217\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5501 - val_loss: 0.9450\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5439 - val_loss: 0.8076\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5382 - val_loss: 0.7231\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5327 - val_loss: 0.6515\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5274 - val_loss: 0.6054\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5225 - val_loss: 0.5664\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5178 - val_loss: 0.5132\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5132 - val_loss: 0.5008\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5090 - val_loss: 0.4816\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5050 - val_loss: 0.4728\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 0.4691\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4974 - val_loss: 0.4676\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4940 - val_loss: 0.4689\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4906 - val_loss: 0.4868\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4876 - val_loss: 0.4828\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.4920\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4817 - val_loss: 0.5168\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4790 - val_loss: 0.5152\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4762 - val_loss: 0.5284\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4737 - val_loss: 0.5220\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4714 - val_loss: 0.5465\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4691 - val_loss: 0.5706\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4797\n",
      "[CV] END learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21; total time=  31.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.8756 - val_loss: 6.9173\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2864 - val_loss: 6.6747\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6179 - val_loss: 3.5732\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2764 - val_loss: 1.8960\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0802 - val_loss: 1.1489\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9607 - val_loss: 0.9289\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8804 - val_loss: 0.8843\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8248 - val_loss: 0.9169\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7878 - val_loss: 0.8685\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7607 - val_loss: 0.8110\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7403 - val_loss: 0.8152\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7252 - val_loss: 0.7826\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7127 - val_loss: 0.7401\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7017 - val_loss: 0.7262\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6918 - val_loss: 0.7021\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6829 - val_loss: 0.7072\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6746 - val_loss: 0.6870\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6669 - val_loss: 0.6792\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6591 - val_loss: 0.6793\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6524 - val_loss: 0.6671\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6450 - val_loss: 0.6574\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6382 - val_loss: 0.6510\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6315 - val_loss: 0.6371\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6249 - val_loss: 0.6262\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6186 - val_loss: 0.6212\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6125 - val_loss: 0.6121\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6062 - val_loss: 0.6163\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6006 - val_loss: 0.6026\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5948 - val_loss: 0.5950\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5894 - val_loss: 0.5894\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5839 - val_loss: 0.5890\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5787 - val_loss: 0.5783\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5733 - val_loss: 0.5806\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5687 - val_loss: 0.5650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5635 - val_loss: 0.5608\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5586 - val_loss: 0.5510\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5539 - val_loss: 0.5440\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.5397\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5443 - val_loss: 0.5329\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5397 - val_loss: 0.5280\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5351 - val_loss: 0.5192\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5309 - val_loss: 0.5142\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5266 - val_loss: 0.5093\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5226 - val_loss: 0.5042\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5184 - val_loss: 0.4995\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5145 - val_loss: 0.4955\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5107 - val_loss: 0.4899\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5070 - val_loss: 0.4859\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4818\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 0.4780\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4962 - val_loss: 0.4745\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 0.4710\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4896 - val_loss: 0.4683\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4863 - val_loss: 0.4662\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4831 - val_loss: 0.4654\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4799 - val_loss: 0.4643\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4770 - val_loss: 0.4594\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4741 - val_loss: 0.4580\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4711 - val_loss: 0.4565\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4681 - val_loss: 0.4512\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4655 - val_loss: 0.4545\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4628 - val_loss: 0.4558\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4603 - val_loss: 0.4500\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4579 - val_loss: 0.4476\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4555 - val_loss: 0.4532\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4533 - val_loss: 0.4526\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4511 - val_loss: 0.4451\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4490 - val_loss: 0.4481\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.4526\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4450 - val_loss: 0.4463\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4430 - val_loss: 0.4420\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4412 - val_loss: 0.4465\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4394 - val_loss: 0.4440\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4496\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4361 - val_loss: 0.4535\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4344 - val_loss: 0.4515\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4471\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4313 - val_loss: 0.4445\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4299 - val_loss: 0.4501\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4283 - val_loss: 0.4658\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4272 - val_loss: 0.4600\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4346\n",
      "[CV] END learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21; total time=  51.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5662 - val_loss: 40.4582\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1544 - val_loss: 8.9607\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6507 - val_loss: 0.5055\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.4442\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.4147\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.4014\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4218 - val_loss: 0.3908\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.3850\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4103 - val_loss: 0.3827\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.3767\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4038 - val_loss: 0.3771\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.3752\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.3709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.3703\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.3675\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.3668\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.3666\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.3642\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.3647\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3637\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3660\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3833 - val_loss: 0.3641\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3758\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3668\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.3671\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.3671\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.3660\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.3677\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.3689\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3700\n",
      "121/121 [==============================] - 0s 954us/step - loss: 0.3957\n",
      "[CV] END learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22; total time=  14.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3047 - val_loss: 10.0970\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6221 - val_loss: 2.5046\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 0.7920\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.4360\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.4178\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.4086\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4154\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.4350\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.5384\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.5410\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.6505\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.6085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.6905\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 0.8813\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.8864\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3962 - val_loss: 1.0357\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4066\n",
      "[CV] END learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22; total time=   7.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2613 - val_loss: 11.3752\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 13.4813\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6249 - val_loss: 23.3676\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8010 - val_loss: 11.9182\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5965 - val_loss: 0.9407\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.4399\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.4348\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.4317\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.4109\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4362 - val_loss: 0.4035\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.3967\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.3938\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4192 - val_loss: 0.3907\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.3884\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.3855\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.3837\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4052 - val_loss: 0.3948\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.4107\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.3933\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.3881\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.3848\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.3869\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.3941\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.3862\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.3811\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 0.3827\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3895 - val_loss: 0.3872\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 0.3950\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3895 - val_loss: 0.3947\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3887 - val_loss: 0.3905\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3852\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3810\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.3726\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3886\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3819\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.3779\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3797 - val_loss: 0.3694\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3809\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.3632\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.3724\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3828\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3762\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3673\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.3695\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.3758\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3704\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3702 - val_loss: 0.3599\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3622\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3780\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3765\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3822\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3700\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3718\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3637\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3654 - val_loss: 0.3589\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3654 - val_loss: 0.3756\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.3816\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.3565\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3633 - val_loss: 0.3759\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.3576\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 0.3565\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.3807\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3615 - val_loss: 0.3683\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 0.3424\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.3631\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3597 - val_loss: 0.3450\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.3821\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.3396\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3579 - val_loss: 0.3733\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.3407\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.3448\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.3470\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3571 - val_loss: 0.3398\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3801\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.4094\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.3393\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.3533\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3378\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3487\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.3358\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3865\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3351\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3979\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3530 - val_loss: 0.3459\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3534\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.3647\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3514 - val_loss: 0.3352\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.3803\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.3465\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.3985\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 0.3979\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.3766\n",
      "121/121 [==============================] - 0s 982us/step - loss: 0.3493\n",
      "[CV] END learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22; total time=  43.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0760 - val_loss: 4.4945\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8320 - val_loss: 3.2735\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9429 - val_loss: 2.4880\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3027 - val_loss: 1.9808\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8383 - val_loss: 1.6503\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4999 - val_loss: 1.4420\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2529 - val_loss: 1.3049\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0714 - val_loss: 1.2142\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 1.1400\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8394 - val_loss: 1.1000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7663 - val_loss: 1.0725\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7122 - val_loss: 1.0337\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6716 - val_loss: 1.0235\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6415 - val_loss: 1.0172\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.9937\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.9841\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5892 - val_loss: 0.9758\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 0.9722\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5720 - val_loss: 0.9689\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5663 - val_loss: 0.9640\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5620 - val_loss: 0.9432\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5585 - val_loss: 0.9391\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5558 - val_loss: 0.9336\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.9275\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.9155\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5505 - val_loss: 0.8964\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5491 - val_loss: 0.9008\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 0.8834\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 0.8825\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.8743\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.8668\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 0.8545\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 0.8543\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5439 - val_loss: 0.8518\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.8385\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.8439\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 0.8096\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.8232\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 0.8161\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.8164\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 0.8240\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.8143\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 0.8059\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.8159\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5392 - val_loss: 0.8175\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.8115\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5385 - val_loss: 0.8173\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.8199\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.8223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5375 - val_loss: 0.8323\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5373 - val_loss: 0.8315\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.8271\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 0.8261\n",
      "121/121 [==============================] - 0s 956us/step - loss: 0.5402\n",
      "[CV] END learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49; total time=  21.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.7558 - val_loss: 7.2818\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.3079 - val_loss: 6.2063\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.2930 - val_loss: 5.5063\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.5713 - val_loss: 5.0605\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0513 - val_loss: 4.7965\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6730 - val_loss: 4.6618\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3952 - val_loss: 4.6214\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1899 - val_loss: 4.6524\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0368 - val_loss: 4.7339\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 4.8519\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8356 - val_loss: 5.0021\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7699 - val_loss: 5.1749\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7199 - val_loss: 5.3661\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 5.5672\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6519 - val_loss: 5.7799\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 6.0007\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 6.2270\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7734\n",
      "[CV] END learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49; total time=   7.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.9856 - val_loss: 25.4042\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.0575 - val_loss: 16.6415\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.7860 - val_loss: 10.9459\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9193 - val_loss: 7.2221\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3107 - val_loss: 4.8449\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8768 - val_loss: 3.2984\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5615 - val_loss: 2.2966\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3297 - val_loss: 1.6492\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1579 - val_loss: 1.2529\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0295 - val_loss: 1.0126\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.8603\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8600 - val_loss: 0.7765\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8045 - val_loss: 0.7308\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7619 - val_loss: 0.7103\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7290 - val_loss: 0.7034\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7035 - val_loss: 0.7111\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6836 - val_loss: 0.7196\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6679 - val_loss: 0.7296\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6553 - val_loss: 0.7509\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6454 - val_loss: 0.7644\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6371 - val_loss: 0.7770\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.7904\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.7942\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.8020\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.8079\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6176\n",
      "[CV] END learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49; total time=  10.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3337 - val_loss: 3.9577\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6357 - val_loss: 2.0164\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5240 - val_loss: 0.4793\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4647 - val_loss: 0.4378\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4337 - val_loss: 0.4004\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4150 - val_loss: 0.4392\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.3839\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3919 - val_loss: 0.4476\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.4017\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.4103\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3589\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.3623\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.4084\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.4294\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3490\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.4363\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3576 - val_loss: 0.3882\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.4057\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.4190\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3518\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 0.4467\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.3601\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.4319\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.4503\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.5967\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3719\n",
      "[CV] END learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42; total time=  13.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2524 - val_loss: 6.7817\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5988 - val_loss: 1.5297\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5158 - val_loss: 0.5310\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4683 - val_loss: 0.4277\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4377 - val_loss: 0.4337\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4190 - val_loss: 0.3943\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 0.3795\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4034\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4787\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3823 - val_loss: 0.5374\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3768 - val_loss: 0.5970\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.6383\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.7128\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.8062\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.8122\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.8960\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.8671\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3812\n",
      "[CV] END learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42; total time=  10.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2710 - val_loss: 2.7774\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 2.0040\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5253 - val_loss: 0.7771\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4847 - val_loss: 0.8078\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4513 - val_loss: 0.4633\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.5648\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4083 - val_loss: 0.4097\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4403\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4142\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.8058\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4151\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.3861\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.4763\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3698\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3689 - val_loss: 0.6224\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3696 - val_loss: 0.4951\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.4926\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3636 - val_loss: 0.3461\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.4009\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.3371\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3491\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.3388\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4602\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.5029\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3524 - val_loss: 0.5038\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3318\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3360\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.4703\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3488 - val_loss: 0.3562\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3793\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3447 - val_loss: 0.3459\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3819\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.3307\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3418 - val_loss: 0.3356\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3262\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3932\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.8129\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.8624\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3438 - val_loss: 2.2618\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 2.2740\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 2.0410\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.8364\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.6053\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3387 - val_loss: 0.3236\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.3875\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3217\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3212\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.4537\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3319 - val_loss: 0.3215\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3741\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3208\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.3177\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3187\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3180\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3259 - val_loss: 0.3244\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.3285\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3265 - val_loss: 0.3203\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3250 - val_loss: 0.3415\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3254 - val_loss: 0.3783\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3244 - val_loss: 0.3534\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3241 - val_loss: 0.3211\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3226 - val_loss: 0.3142\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.3190\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3220 - val_loss: 0.3165\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.3740\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.4058\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3220 - val_loss: 0.5253\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3213 - val_loss: 0.5614\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.5455\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3219 - val_loss: 0.4850\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.4637\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3201 - val_loss: 0.6262\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3268\n",
      "[CV] END learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42; total time=  39.2s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8064 - val_loss: 14.1998\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6860 - val_loss: 12.2937\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5759 - val_loss: 3.8196\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.5331\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4031\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4007 - val_loss: 0.3996\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.3764\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3879 - val_loss: 0.3733\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.3713\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3727\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.3546\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.3733\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3639\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.3460\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3634 - val_loss: 0.3528\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.3418\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.3582\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3744\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3355\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3958\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3333\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.4074\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.4172\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3456\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3513\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3439 - val_loss: 0.3476\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3457 - val_loss: 0.3272\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3380\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3295\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3411 - val_loss: 0.3730\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.3249\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3414\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3375 - val_loss: 0.3220\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3214\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3349 - val_loss: 0.3365\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3441\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3394\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3186\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3359 - val_loss: 0.3154\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3326 - val_loss: 0.3422\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3332 - val_loss: 0.3662\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3313 - val_loss: 0.3170\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3469\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3306 - val_loss: 0.3178\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3135\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3244 - val_loss: 0.3159\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3244 - val_loss: 0.3123\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.3788\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3277 - val_loss: 0.3457\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3112\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3219 - val_loss: 0.3403\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3220 - val_loss: 0.4055\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3992\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3203 - val_loss: 0.3146\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3193 - val_loss: 0.3142\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3256 - val_loss: 0.3099\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3202 - val_loss: 0.3091\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3165 - val_loss: 0.4254\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3208 - val_loss: 0.3051\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.3059\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3104\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3442\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3250 - val_loss: 0.3347\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3811 - val_loss: 0.3151\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3194 - val_loss: 0.3066\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3165 - val_loss: 0.3107\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3202 - val_loss: 0.3094\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3144 - val_loss: 0.3115\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3155 - val_loss: 0.3118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fcd540f1c70&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7fcd4f6c1c70&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fcd540f1c70&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7fcd4f6c1c70&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fcd540f1c70&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fcd540f1c70&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7fcd540f1c70>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fcd4f6c1c70>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because of flexibility of Keras, there are a tons of options to tweak. One simple option \n",
    "# to use GridSearchCV or RandomizedSearchCV to explore the hyperparameter space.\n",
    "#\n",
    "# We don’t want to train and evaluate a single model like this, though we\n",
    "# want to train hundreds of variants and see which one performs best on the\n",
    "# validation set. Since there are many hyperparameters, it is preferable to use a \n",
    "# randomized search rather than grid search.\n",
    "\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.008339092654580042, 'n_hidden': 1, 'n_neurons': 38}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3575756947199504"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x7fcd555c1d00>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 972us/step - loss: 0.3276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.32757094502449036"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcd4f6c1a90>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 970us/step - loss: 0.3276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32757094502449036"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

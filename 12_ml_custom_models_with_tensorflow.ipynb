{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Models and Training with TensorFlow\n",
    "\n",
    "\n",
    "So what does TensorFlow offer? Here’s a summary:\n",
    "\n",
    "- Its core is very similar to NumPy, but with GPU support. It supports distributed computing (across multiple devices and servers).\n",
    "\n",
    "- It includes a kind of just-in-time (JIT) compiler that allows it to optimize computations for speed and memory usage. It works by extracting the computation graph from a Python function, then optimizing it (e.g., by pruning unused nodes), and finally running it efficiently (e.g., by automatically running independent operations in parallel).\n",
    "\n",
    "- Computation graphs can be exported to a portable format, so you can train a TensorFlow model in one environment (e.g., using Python on Linux) and run it in another (e.g., using Java on an Android device).\n",
    "\n",
    "\n",
    "- **Using TensorFlow like NumPy**\n",
    "    - Tensors and NumPy\n",
    "    - Type Conversion\n",
    "    - Variables\n",
    "    - Other Data Structures\n",
    "- **Customizing Models and Training Algorithms**\n",
    "    - Custom Loss Functions\n",
    "    - Saving and Loading Models That Contain Custom Components\n",
    "    - Custom Activation Functions, Initializers, Regularizers, and Constraints\n",
    "    - Custom Metrics\n",
    "    - Custom Layers\n",
    "    - Custom Models\n",
    "    - Losses and Metrics Based on Model Internals\n",
    "    - Computing Gradients Using Autodiff\n",
    "    - Custom Training Loops\n",
    "- **TensorFlow Functions and Graphs**\n",
    "    - AutoGraph and Tracing\n",
    "    - TF Function Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.4 is required in this notebook\n",
    "# Earlier 2.x versions will mostly work the same, but with a few bugs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(f'Tensorflow version : {tf.__version__}')\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "    \n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "RESOURCE_DIR = os.path.join(PROJECT_ROOT_DIR, \"resource\")\n",
    "\n",
    "def save_fig(fig, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(RESOURCE_DIR, fig + \".\" + fig_extension)\n",
    "    print(\"Saving figure...\", fig)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Using TensorFlow like NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Tensors and operations\n",
    "\n",
    "TensorFlow’s API revolves around tensors, which flow from operation to operation—hence the name TensorFlow. A tensor is usually a multidimensional array (exactly like a NumPy ndarray ), but it can also hold a scalar (a simple value, such as 42 ). These tensors will be important when we create custom cost functions, custom metrics, custom layers, and\n",
    "more.\n",
    "\n",
    "You can create a tensor with tf.constant() . For example, here is a tensor representing a matrix with two rows and three columns of floats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 20:43:03.181938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:03.224762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:03.225223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:03.228170: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 20:43:03.229561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:03.230345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:03.230718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:04.452252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:04.453075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:04.453329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 20:43:04.453787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4305 MB memory:  -> device: 0, name: Quadro RTX 3000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just like an ndarray , a tf.Tensor has a shape and a data type (dtype)\n",
    "\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Indexing\n",
    "\n",
    "Indexing works much like in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Ops\n",
    "\n",
    "Most importantly, all sorts of tensor operations are available.\n",
    "\n",
    "You will find all the basic math operations you need ( tf.add(), tf.multiply(), tf.square(), tf.exp(), tf.sqrt(), etc.) and most operations that you can find in NumPy (e.g., tf.reshape(), tf.squeeze(), tf.tile() ). \n",
    "\n",
    "Some functions have a different name than in NumPy; for instance, tf.reduce_mean(), tf.reduce_sum(), tf.reduce_max(), and tf.math.log() are the equivalent of np.mean(),\n",
    "np.sum(), np.max() and np.log()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Using `keras.backend`\n",
    "\n",
    "The Keras API has its own low-level API, located in keras.backend . It includes functions like square(), exp(), and sqrt(). In tf.keras, these functions generally just call the corresponding TensorFlow operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Tensors and NumPy\n",
    "\n",
    "Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set dtype=tf.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Type Conversions\n",
    "\n",
    "Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types. For example, you cannot add a float tensor and an integer tensor, and you cannot even add a 32-bit float and a 64-bit float.\n",
    "\n",
    "This may be a bit annoying at first, but remember that it’s for a good cause! And of course you can use tf.cast() when you really need to convert types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Variables\n",
    "\n",
    "The tf.Tensor values we’ve seen so far are immutable: you cannot modify them. This means that we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation. Plus, other parameters may also need to change over time (e.g., a momentum optimizer keeps track of past gradients). What we need is a _tf.Variable_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Other Data Structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Strings\n",
    "\n",
    "Are regular tensors of type tf.string . These represent byte strings, not Unicode strings, so if you create a string tensor using a Unicode string (e.g., a regular Python 3 string like \"café\" ), then it will get encoded to UTF-8 automatically (e.g., b\"caf\\xc3\\xa9\" ). Alternatively, you can represent Unicode strings using tensors of type tf.int32 , where each item represents a Unicode code point (e.g., [ 99, 97, 102, 233] )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Ragged tensors\n",
    "\n",
    "Represent static lists of lists of tensors, where every tensor has the same shape and data type. The tf.ragged package contains operations for ragged tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71],\n",
      " [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Sparse tensors\n",
    "\n",
    "Efficiently represent tensors containing mostly zeros. The tf.sparse package contains operations for sparse tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{function_node __wrapped__SparseToDense_device_/job:localhost/replica:0/task:0/device:GPU:0}} indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      "\n",
      "\t [[{{node SparseToDense}}]] [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Sets\n",
    "\n",
    "Are represented as regular tensors (or sparse tensors). For example, tf.constant([[1, 2], [3, 4]]) represents the two sets {1, 2} and {3, 4}. More generally, each set is represented by a vector in the tensor’s last axis. You can manipulate sets using operations from the tf.sets package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Tensor Arrays\n",
    "\n",
    "Are lists of tensors. They have a fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Customizing Models and Training Algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Suppose you want to train a regression model, but your training set is a bit noisy. Of course, you start by trying to clean up your dataset by removing or fixing the outliers, but that turns out to be insufficient; the dataset is still noisy. Which loss function should you use? The mean squared error might penalize large errors too much and cause your model to be imprecise. The mean absolute error would not penalize outliers as much, but training might take a while to converge, and the trained model mightnot be very precise. \n",
    "\n",
    "This is probably a good time to use the Huber loss instead of the good old MSE. The Huber loss isnot currently part of the official Keras API, but it is available in tf.keras (just use an instance of the keras.losses.Huber class). But let’s pretend it’s not there: implementing it is easy as pie! Just create a function that takes the labels and predictions as arguments, and use TensorFlow operations to compute every instance’s loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "And that’s it! For each batch during training, Keras will call the huber_fn() function to compute the loss and use it to perform a Gradient Descent step. Moreover, it will keep track of the total loss since the beginning of the epoch, and it will display the mean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 21:16:48.788502: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x3767e090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-04 21:16:48.788531: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 3000, Compute Capability 7.5\n",
      "2023-04-04 21:16:48.829480: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-04 21:16:49.242123: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 3ms/step - loss: 0.5550 - mae: 0.9161 - val_loss: 0.2337 - val_mae: 0.5315\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2208 - mae: 0.5188 - val_loss: 0.2045 - val_mae: 0.4976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16a87f47f0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Saving/Loading Models with Custom Objects\n",
    "\n",
    "But what happens to this custom loss when you save the model?\n",
    "\n",
    "Saving a model containing a custom loss function works fine, as Keras saves the name of the function. Whenever you load it, you’ll need to provide a dictionary that maps the function name to the actual function. More generally, when you load a model containing custom objects, you need to map the names to the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_a_custom_loss.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2069 - mae: 0.5005 - val_loss: 0.1915 - val_mae: 0.4775\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1998 - mae: 0.4899 - val_loss: 0.2097 - val_mae: 0.4959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16a8445c10>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2125 - mae: 0.4780 - val_loss: 0.1955 - val_mae: 0.4582\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2094 - mae: 0.4732 - val_loss: 0.2204 - val_mae: 0.4761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16a81a09a0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.2066 - mae: 0.4695 - val_loss: 0.1930 - val_mae: 0.4529\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2044 - mae: 0.4660 - val_loss: 0.2190 - val_mae: 0.4718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16a8373fa0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.8050 - mae: 0.9523 - val_loss: 0.3326 - val_mae: 0.5465\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2391 - mae: 0.5083 - val_loss: 0.2492 - val_mae: 0.5021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1695fddb50>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2272 - mae: 0.4968 - val_loss: 0.2427 - val_mae: 0.4898\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2227 - mae: 0.4910 - val_loss: 0.2181 - val_mae: 0.4795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1695fa7820>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Custom Activation Functions, Initializers, Regularizers, and Constraints\n",
    "\n",
    "Most Keras functionalities, such as losses, regularizers, constraints, initializers, metrics, activation functions, layers, and even full models, can be customized in very much the same way. Most of the time, you will justneed to write a simple function with the appropriate inputs and outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are examples of a custom activation function (equivalent to \n",
    "# keras.activations.softplus() or tf.nn.softplus()), a custom\n",
    "# Glorot initializer (equivalent to keras.initializers.glorot_normal() ), \n",
    "# a custom ℓ 1 regularizer (equivalent to keras.regularizers.l1(0.01) ), \n",
    "# and a custom constraint that ensures weights are all positive (equivalent to\n",
    "# keras.constraints.nonneg() or tf.nn.relu()).\n",
    "\n",
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5193 - mae: 0.4947 - val_loss: 0.7957 - val_mae: 0.4834\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4979 - mae: 0.4872 - val_loss: 0.7586 - val_mae: 0.4855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1695c4da00>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"trained_models/my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If a function has hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class, such as keras.regularizers.Regularizer, keras.constraints.Constraint, keras.initializers.Initializer, or keras.layers.Layer (for any layer, including activation functions). Much like we did for the custom loss, here is a simple class for _ℓ_ 1 regularization that saves its factor hyperparameter (this time we do not need to call the parent constructor or the get_config() method, as they are not defined by the parent class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.7522 - mae: 0.9654 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6208 - mae: 0.5337 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1695c1ed30>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"trained_models/my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Custom Metrics\n",
    "\n",
    "Losses and metrics are conceptually not the same thing: losses (e.g., cross entropy) are used by Gradient Descent to train a model, so they must be differentiable (at least where they are evaluated), and their gradients should not be 0 everywhere. Plus, it’s OK if they are not easily interpretable by humans. In contrast, metrics (e.g., accuracy) are used to evaluate a model: they must be more easily interpretable, and they can be non-differentiable or have 0 gradients everywhere.\n",
    "\n",
    "That said, in most cases, defining a custom metric function is exactly the same as defining a custom loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8975 - huber_fn: 0.8171\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5310 - huber_fn: 0.2580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1695a89070>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1152 - huber_fn: 0.2342\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1110 - huber_fn: 0.2254\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11521773040294647, 0.11623532250145789)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Streaming metrics\n",
    "\n",
    "For each batch during training, Keras will compute this metric and keep track of its mean since the beginning of the epoch. Most of the time, this is exactly what you want. But not always! Consider a binary classifier’s precision, for example. As we saw in, precision is the number of true positives divided by the number of positive predictions (including both true positives and false positives). Suppose the model made five positive predictions in the first batch, four of which were correct: that’s 80% precision. Then suppose the model made three positive predictions in the second batch, but they were all incorrect: that’s 0% precision for the second batch. If you just compute the mean of these two precisions, yo get 40%. But wait a second—that’s not the model’s precision over these two batches! Indeed, there were a total of four true positives (4 + 0) out of eight positive predictions (5 + 3), so the overall precision is 50%, not 40%. What we need is an object that can keep track of the number of true positives and the number of false positives and that can compute their ratio when requested. This is precisely what the keras.metrics.Precision class does.\n",
    "\n",
    "In the example below, we created a Precision object, then we used it like a function, passing it the labels and predictions for the first batch, then for the second batch (note that we could also have passed sample weights). We used the same number of true and false positives as in the example we just discussed. After the first batch, it returns a precision of 80%; then after these scond batch, it returns 50% (which is the overall precision so far, not the second batch’s precision). This is called a streaming metric (or stateful metric), as it is gradually updated, batch after batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Creating a streaming metric:\n",
    "\n",
    "If you need to create such a streaming metric, create a subclass of the keras.metrics.Metric class. Here is a simple example that keeps track of the total Huber loss and the number of instances seen so far. When asked for the result, it returns the ratio, which is simply the mean Huber loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 592us/step - loss: 1.5182 - huber_metric: 1.5182\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.2909 - huber_metric: 0.2909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc000fdfbd0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_model_with_a_custom_metric.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8630 - huber_metric: 0.8630\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2536 - huber_metric: 0.2536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1692049610>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: In TF 2.2, tf.keras adds an extra first metric in `model.metrics` at position 0 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the `HuberMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4242 - HuberMetric: 0.8548\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1206 - HuberMetric: 0.2429\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4241766035556793, 0.4241766501176932)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_model_with_a_custom_metric_v2.h5\",\n",
    "                                custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2285 - HuberMetric: 0.2285\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2209 - HuberMetric: 0.2209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f168c4d6610>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Custom Layers\n",
    "\n",
    "You may occasionally want to build an architecture that contains an exotic layer for which TensorFlow does not provide a default implementation. In this case, you will need to create a custom layer. Or you may simply want to build a very repetitive architecture, containing identical blocks of layers repeated many times, and it would be convenient to treat each block of layers as a single layer. For example, if the model is a sequence of layers A, B, C, A, B, C, A, B, C, then you might want to define a custom layer D containing layers A, B, C, so your model would then simply be D, D, D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some layers have no weights, such as keras.layers.Flatten or keras.layers.ReLU . If you want to create a custom layer without any weights, the simplest option is to write a function and wrap it in a keras.layers.Lambda layer. For example, the following layer will apply the exponential function to its inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787948, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.0709 - val_loss: 1.7735\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3811 - val_loss: 0.9533\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8270 - val_loss: 0.5539\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6024 - val_loss: 0.4272\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.3914\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.416515588760376"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To build a custom stateful layer (i.e., a layer with weights), you need to create a subclass of thekeras.layers.Layer class. For example, the following class implements a simplified version of the Dense layer.\n",
    "\n",
    "- The constructor takes all the hyperparameters as arguments (in this example, units and activation ), and importantly it also takes a \\*\\*kwargs argument. It calls the parent constructor, passing it the kwargs : this takes care of standard arguments such as input_shape , trainable , and name . Then it saves the hyperparameters as attributes, converting the activation argument to the appropriate activation function using the keras.activations.get() function (it accepts functions, standard strings like \"relu\" or \"selu\" , or simply None ).\n",
    "\n",
    "- The build() method’s role is to create the layer’s variables by calling the add_weight() method for each weight. The build() method is called the first time the layer is used. At that point, Keras will know the shape of this layer’s inputs, and it will pass it to the build() method, 9 which is often necessary to create some of the weights. For example, we need to know the number of neurons in the previous layer in order to create the connection weights matrix (i.e., the \"kernel\" ): this corresponds to the size of the last dimension of the inputs. At the end of the build() method (and only at the end), you must call the parent’s build() method: this tells Keras that the layer is built (it just sets self.built=True ).\n",
    "\n",
    "- The call() method performs the desired operations. In this case, we compute the matrix multiplication of the inputs X and the layer’s kernel, we add the bias vector, and we apply the activation function to the result, and this gives us the output of the layer.\n",
    "\n",
    "- The compute_output_shape() method simply returns the shape of this layer’s outputs. In this case, it is the same shape as the inputs, except the last dimension is replaced with the number of neurons in the layer. Note that in tf.keras, shapes are instances of the tf.TensorShape class, which you can convert to Python lists using as_list().\n",
    "\n",
    "- The get_config() method is just like in the previous custom classes. Note that we save the activation function’s full configuration by calling keras.activations.serialize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5357 - val_loss: 0.7168\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5550 - val_loss: 0.4559\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4736383855342865"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging of custom layer\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom layer can be called using the functional API like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, whose shape is only partially specified (at this stage, we don't know the batch size, which is why the first dimension is `None`):\n",
    "\n",
    "We can also pass actual data to the custom layer. To test this, let's split each dataset's inputs into two parts, with four features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]\n",
    "\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# Printing the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now notice that the shapes are fully specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a more complete model using the functional API (this is just a toy example, don't expect awesome performance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
    "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "353/363 [============================>.] - ETA: 0s - loss: 3.1042X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 3.0484 - val_loss: 23.7909\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5111 - val_loss: 9.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1695e42430>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
    "          validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple model that uses this custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1898 - val_loss: 0.7901\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0205 - val_loss: 0.7508\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.7405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7405170202255249"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Custom Models\n",
    "\n",
    "Creating custom model classes is nothing but the Subclassing API. It’s straightforward: subclass the keras.Model class, create layers and variables in the constructor, and implement the call() method to do whatever you want the model to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f167454e790>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import image as mpimg\n",
    "\n",
    "image = mpimg.imread(RESOURCE_DIR + '/residual.png')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The inputs go through a first dense layer, then through a residual block composed of two dense layers and an addition operation (a residual block adds its inputs to its outputs), then through this same residual block three more times, then through a second residual block, and the final result goes through a dense output layer. Note that this model does not make much sense; it’s just an example to illustrate the fact that you can easily build any kind of model you want, even one that contains loops and skip connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 3s 3ms/step - loss: 13.0450\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.7879\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8072\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.9934\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3364\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 2.2085\n",
      "162/162 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(8, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16743d9c10>, 139734416480272), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f167444c5e0>, 139734416479408), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16743922e0>, 139734416707968), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f167433a190>, 139734416707632), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f167435be20>, 139734416709536), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1674300d00>, 139734416708864), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16743299d0>, 139734416776640), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16742d7880>, 139734416776976), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1674282550>, 139734416720704), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16742ab400>, 139734416721040), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 1), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16742540d0>, 139734416730896), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1674276f40>, 139734416730416), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(8, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16743d9c10>, 139734416480272), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f167444c5e0>, 139734416479408), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16743922e0>, 139734416707968), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f167433a190>, 139734416707632), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f167435be20>, 139734416709536), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1674300d00>, 139734416708864), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16743299d0>, 139734416776640), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16742d7880>, 139734416776976), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 30), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1674282550>, 139734416720704), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16742ab400>, 139734416721040), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(30, 1), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f16742540d0>, 139734416730896), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1674276f40>, 139734416730416), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_models/my_custom_model.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_models/my_custom_model.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"trained_models/my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"trained_models/my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 3s 4ms/step - loss: 1.1567\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.0229\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7944\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4038\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5469\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 3s 3ms/step - loss: 1.3691\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6544\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6523\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4001\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4660\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 1.0704\n",
      "162/162 [==============================] - 0s 936us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Losses and Metrics Based on Model Internals\n",
    "\n",
    "The custom losses and metrics we defined earlier were all based on the labels and the predictions (and optionally sample weights). There will be times when you want to define losses based on other parts of your model, such as the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of your model.\n",
    "\n",
    "To define a custom loss based on model internals, compute it based on any part of the model you want, then pass the result to the add_loss()method.For example, let’s build a custom regression MLP (_multi-layer perceptron_) model  composed of a stack of five hidden layers plus an output layer. This custom model will also have an auxiliary output on top of the upper hidden layer. \n",
    "\n",
    "The loss associated to this auxiliary output will be called the reconstruction loss: it is the mean squared difference between the reconstruction and the inputs. By adding this reconstruction loss to the main loss, we will encourage the model to preserve as much information as possible through the hidden layers—even information that is not directly useful for the regression task itself. In practice, this loss sometimes improves generalization (it is a regularization loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the following code has two differences with the code in the book:\n",
    "1. It creates a `keras.metrics.Mean()` metric in the constructor and uses it in the `call()` method to track the mean reconstruction loss. Since we only want to do this during training, we add a `training` argument to the `call()` method, and if `training` is `True`, then we update `reconstruction_mean` and we call `self.add_metric()` to ensure it's displayed properly.\n",
    "2. Due to an issue introduced in TF 2.2 ([#46858](https://github.com/tensorflow/tensorflow/issues/46858)), we must not call `super().build()` inside the `build()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        #super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- The constructor creates the DNN with five dense hidden layers and one dense output layer.The build() method creates an extra dense layer which will be used to reconstruct the inputs of the model. It must be created here because its number of units must be equal to the number of inputs, and this number is unknown before the build() method is called.\n",
    "\n",
    "- The call() method processes the inputs through all five hidden layers, then passes the result through the reconstruction layer, which produces the reconstruction. \n",
    "\n",
    "- Then the call() method computes the reconstruction loss (the mean squared difference between the reconstruction and the inputs), and adds it to the model’s list of losses using the add_loss() method. Notice that we scale down the reconstruction loss by multiplying it by 0.05 (this is a hyperparameter you can tune). This ensures that the reconstruction loss does not dominate the main loss.\n",
    "\n",
    "- Finally, the call() method passes the output of the hidden layers to the output layer and returns its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 4ms/step - loss: 0.7944 - reconstruction_error: 1.0253\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4213 - reconstruction_error: 0.4831\n",
      "162/162 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Computing Gradients with Autodiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Custom Training Loops\n",
    "\n",
    "In some rare cases, the fit() method may not be flexible enough for what you need to do. Since the fit() method only uses one optimizer (the one that we specify when compiling the model), some implementations uses two different optimizers. Hence custom loops are required.\n",
    "\n",
    "You may also like to write custom training loops simply to feel more confident that they do precisely what you intend them to do (perhaps you are unsure about some details of the fit() method). It can sometimes feel safer to make everything explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancier version with a progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.7270 - mean_absolute_error: 0.57851\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.7437 - mean_absolute_error: 0.5247\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6483 - mean_absolute_error: 0.5165\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6435 - mean_absolute_error: 0.5180\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6505 - mean_absolute_error: 0.5238\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We create two nested loops: one for the epochs, the other for the batches within an epoch. \n",
    "\n",
    "- Then we sample a random batch from the training set.\n",
    "\n",
    "- Inside the tf.GradientTape() block, we make a prediction for one batch (using the model as a function), and we compute the loss: it is equal to the main loss plus the other losses (in this model, there is one regularization loss per layer). Since the mean_squared_error() function returns one loss per instance, we compute the mean over the batch using tf.reduce_mean() (if you wanted to apply different weights to each instance, this is where you would do it). The regularization losses are already reduced to a single scalar each, so we just need to sum them (using tf.add_n() , which sums multiple tensors of the same shape and data type).\n",
    "\n",
    "- Next, we ask the tape to compute the gradient of the loss with regard to each trainable variable (not all variables!), and we apply them to the optimizer to perform a Gradient Descent step. \n",
    "\n",
    "- Then we update the mean loss and the metrics (over the current epoch), and we display the status bar.\n",
    "\n",
    "- At the end of each epoch, we display the status bar again to make it look complete 13 and to print a line feed, and we reset the states of the mean loss and the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911ccc0821324e99b156302727dbf9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c8135ff59540c085b55653e6d69243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06190b83afc348e999aeb3a3c523aae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44eb6b7d11b74a4aa9af17892e2a8ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c62578a1aa24b7d96201cc285025e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a0328d0c5b4112995297e67bc290b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm.notebook import trange\n",
    "    from collections import OrderedDict\n",
    "    with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))                    \n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## TensorFlow Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow 1, graphs were unavoidable (as were the complexities that came with them) because they were a central part of TensorFlow’s API. In TensorFlow 2, they are still there, but not as central, and they’re much (much!) simpler to use. To show just how simple, let’s start with a trivial function that computes the cube of its input.\n",
    "\n",
    "We can obviously call this function with a Python value, such as an int or a float, or we can call it with a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, let’s use tf.function() to convert this Python function to a **TensorFlow Function**.\n",
    "This TF Function can then be used exactly like the original Python function, and it will return the same result (but as tensors).\n",
    "\n",
    "Under the hood, tf.function() analyzed the computations performed by the cube() function and generated an equivalent computation graph! As you can see, it was rather painless. Alternatively, we could have used tf.function as a decorator; this is actually more common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f16600afc10>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7f16600a5cd0>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Exploring Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7f16600a5cd0>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_cube_1073862\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Autograph and Tracing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So how does TensorFlow generate graphs? It starts by analyzing the Python function’s source code to capture all the control flow statements, such as for loops, while loops, and if statements, as well as break , continue , and return statements. This first step is called _AutoGraph_. The reason TensorFlow has to analyze the source code is that Python does not provide any other way to capture control flow statements: it offers magic methods like __add__() and __mul__() to capture operators like + and \\*, but there are no __while__() or __if__() magic methods. After analyzing the function’s code, AutoGraph outputs an upgraded version of that function in which all the control flow statements are replaced by the appropriate TensorFlow operations, such as tf.while_loop() for loops and tf.cond() for if statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How TF Functions Trace Python Functions to Extract Their Computation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f166005d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f166005d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x7f166005d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x7f166005d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # New shape: trace!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a particular input signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Using Autograph To Capture Control Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ssenapati/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ssenapati/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### TF Functions Rules\n",
    "\n",
    "Most of the time, converting a Python function that performs TensorFlow operations into a TF Function is trivial: decorate it with @tf.function or let Keras take care of it for you. However, there are a few rules to respect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x):\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            (x,) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Using TF Functions with tf.keras (or Not)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "355/363 [============================>.] - ETA: 0s - loss: 1.4265 - my_mae: 0.8175Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.4061 - my_mae: 0.8109 - val_loss: 0.5759 - val_my_mae: 0.4838\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4434 - my_mae: 0.4783 - val_loss: 0.4691 - val_my_mae: 0.4673\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4236 - my_mae: 0.4733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4235876202583313, 0.47330442070961]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, **kwargs)` in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the custom code will be called at each iteration. Let's fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "WARNING:tensorflow:5 out of the last 7241 calls to <function _BaseOptimizer._update_step_xla at 0x7f1640517700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7241 calls to <function _BaseOptimizer._update_step_xla at 0x7f1640517700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7242 calls to <function _BaseOptimizer._update_step_xla at 0x7f1640517700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7242 calls to <function _BaseOptimizer._update_step_xla at 0x7f1640517700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.600638389587402, 2.0552163124084473]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5947749018669128"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Custom Optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.legacy.Optimizer): # wont work without legacy \n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.6146\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2207\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7529\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6446\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1674362910>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
